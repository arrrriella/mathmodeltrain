{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers\n%pip install -U datasets\n%pip install -U accelerate\n%pip install -U peft\n%pip install -U trl\n%pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:08:29.044983Z","iopub.execute_input":"2025-05-14T13:08:29.045283Z","iopub.status.idle":"2025-05-14T13:10:15.742705Z","shell.execute_reply.started":"2025-05-14T13:08:29.045260Z","shell.execute_reply":"2025-05-14T13:10:15.741638Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"token\")\nlogin(token = hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:10:15.744491Z","iopub.execute_input":"2025-05-14T13:10:15.744771Z","iopub.status.idle":"2025-05-14T13:10:16.829169Z","shell.execute_reply.started":"2025-05-14T13:10:15.744747Z","shell.execute_reply":"2025-05-14T13:10:16.828402Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport torch\ndevice = torch.device(\"cuda\")  # для Kaggle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:10:16.829996Z","iopub.execute_input":"2025-05-14T13:10:16.830385Z","iopub.status.idle":"2025-05-14T13:10:21.307540Z","shell.execute_reply.started":"2025-05-14T13:10:16.830356Z","shell.execute_reply":"2025-05-14T13:10:21.306909Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"token\")\nlogin(token = hf_token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Загрузка базовой модели с Hugging Face\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\nfrom datasets import load_dataset\nfrom peft import LoraConfig, get_peft_model\nfrom trl import SFTTrainer\nmodel_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:10:21.308639Z","iopub.execute_input":"2025-05-14T13:10:21.309053Z","iopub.status.idle":"2025-05-14T13:10:49.111121Z","shell.execute_reply.started":"2025-05-14T13:10:21.309033Z","shell.execute_reply":"2025-05-14T13:10:49.110438Z"}},"outputs":[{"name":"stderr","text":"2025-05-14 13:10:32.489905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747228232.663621      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747228232.719546      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68c0fd439d5c4c9bb9dfa8e4d7e2c3f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6768c7506b6540bb8f203bfa21c65bd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a668b3f042147769a78445238cbe168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc00a604f58f451cbafb1c390d5b676c"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_name, \n    device_map=\"auto\",  # Автоматически использует доступный GPU\n    torch_dtype=torch.float16,  # Добавьте это\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:11:53.314364Z","iopub.execute_input":"2025-05-14T13:11:53.314681Z","iopub.status.idle":"2025-05-14T13:12:00.700151Z","shell.execute_reply.started":"2025-05-14T13:11:53.314658Z","shell.execute_reply":"2025-05-14T13:12:00.699658Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ae37f38d2e04fb796703addca99d849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0db85e3f80f84579ab2ab35348c76a9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdaeeb5518594b2d8a01406cb15e70b7"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Загрузка базовой модели с Hugging Face\nfrom datasets import load_dataset\nfrom peft import LoraConfig, get_peft_model\nfrom trl import SFTTrainer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:12:09.110535Z","iopub.execute_input":"2025-05-14T13:12:09.110823Z","iopub.status.idle":"2025-05-14T13:12:09.115046Z","shell.execute_reply.started":"2025-05-14T13:12:09.110801Z","shell.execute_reply":"2025-05-14T13:12:09.114189Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from datasets import load_dataset\n# Загрузка датасета\ndataset = load_dataset(\"gsm8k\", \"main\", split=\"train[:100]\")  # Берем только 1000 примеров\n#dataset = load_dataset(\"gsm8k\", \"main\", split=\"train+test\")\n\"\"\"https://huggingface.co/papers/2402.10176\nhttps://arxiv.org/html/2402.10176v1\nдатасет\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:27:51.213335Z","iopub.execute_input":"2025-05-14T13:27:51.213855Z","iopub.status.idle":"2025-05-14T13:27:55.670387Z","shell.execute_reply.started":"2025-05-14T13:27:51.213831Z","shell.execute_reply":"2025-05-14T13:27:55.669705Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/papers/2402.10176\\nhttps://arxiv.org/html/2402.10176v1\\nдатасет'"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# Обновите параметры обучения\ntraining_args = TrainingArguments(\n    per_device_train_batch_size=8,  # Увеличьте батч\n    gradient_accumulation_steps=4,  # Уменьшите аккумуляцию\n    gradient_checkpointing=True,\n    fp16=True,\n    max_steps=500,  # Обучайте по шагам, а не эпохам\n    optim=\"adamw_8bit\",  # 8-битный Adam\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:28:01.287167Z","iopub.execute_input":"2025-05-14T13:28:01.287863Z","iopub.status.idle":"2025-05-14T13:28:01.316246Z","shell.execute_reply.started":"2025-05-14T13:28:01.287841Z","shell.execute_reply":"2025-05-14T13:28:01.315629Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"\n# Функция форматирования промптов\ndef format_prompt(example):\n    return {\n        \"text\": f\"Реши математическую задачу:\\n{example['question']}\\n### Ответ:\\n{example['answer']}\"\n    }\n\n# Применяем форматирование\ndataset = dataset.map(\n    format_prompt,\n    remove_columns=[\"question\", \"answer\"]\n)\n# Разделение на трейн/тест (меньший тестовый набор)\ndataset = dataset.train_test_split(\n    test_size=0.05,\n    seed=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:28:03.525277Z","iopub.execute_input":"2025-05-14T13:28:03.525643Z","iopub.status.idle":"2025-05-14T13:28:03.556680Z","shell.execute_reply.started":"2025-05-14T13:28:03.525621Z","shell.execute_reply":"2025-05-14T13:28:03.556156Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1d11117e5f7419b9b5fd60809e8da94"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# Настройка LoRA для эффективного дообучения\n'''peft_config = LoraConfig(\n    r=32,\n    lora_alpha=64,\n    target_modules=[\n        \"q_proj\", \"k_proj\", \"v_proj\",  # Модули внимания\n        \"gate_proj\", \"up_proj\", \"down_proj\"  # Модули FFN\n    ],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)'''\n\n# Настройка LoRA - уменьшаем ранг для скорости\npeft_config = LoraConfig(\n    r=4,                       # Уменьшаем ранг для скорости\n    lora_alpha=8,             \n    lora_dropout=0.0,         \n    bias=\"none\",               \n    task_type=\"CAUSAL_LM\"      \n)\nmodel = get_peft_model(model, peft_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:28:27.738414Z","iopub.execute_input":"2025-05-14T13:28:27.739123Z","iopub.status.idle":"2025-05-14T13:28:27.799053Z","shell.execute_reply.started":"2025-05-14T13:28:27.739102Z","shell.execute_reply":"2025-05-14T13:28:27.798331Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Настройка обучения\n# Ускоренные параметры обучения\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,        # Всего 1 эпоха\n    per_device_train_batch_size=16,  # Увеличиваем батч-сайз\n    gradient_accumulation_steps=1,  # Уменьшаем аккумуляцию градиентов\n    label_names=[\"labels\"],  # Добавьте эту строку\n    optim=\"adamw_torch\",\n    save_steps=100,            # Реже сохраняем\n    logging_steps=5,          # Реже логируем\n    learning_rate=5e-4,        # Увеличиваем скорость обучения\n    weight_decay=0.0,          # Отключаем регуляризацию\n    fp16=True,                \n    report_to=\"none\",          # Отключаем отчеты в wandb для скорости\n    gradient_checkpointing=False,#it was true\n    max_steps=20,             # Ограничиваем количество шагов\n    warmup_steps=0,            # Без разогрева\n    logging_first_step=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:29:51.644007Z","iopub.execute_input":"2025-05-14T13:29:51.644695Z","iopub.status.idle":"2025-05-14T13:29:51.672167Z","shell.execute_reply.started":"2025-05-14T13:29:51.644671Z","shell.execute_reply":"2025-05-14T13:29:51.671611Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Настройка тренера (исправленная версия)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    processing_class=tokenizer,  # Заменяем tokenizer на processing_class\n    peft_config=peft_config,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:29:56.297621Z","iopub.execute_input":"2025-05-14T13:29:56.297866Z","iopub.status.idle":"2025-05-14T13:29:56.480958Z","shell.execute_reply.started":"2025-05-14T13:29:56.297850Z","shell.execute_reply":"2025-05-14T13:29:56.480444Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/95 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f09a494addf448dda809799b54596bb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/95 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dbc2ff4f0fa4414abadaed9c7e7a89f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/95 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee596de7eb9745e6ac8d50968dcb9f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/95 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ed3484731c5414d9adc6643ee7e7f43"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# Запускаем обучение\ntrainer.train()\n\n# Сохраняем модель\nmodel.save_pretrained(\"./fine_tuned_model\")\ntokenizer.save_pretrained(\"./fine_tuned_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T13:29:59.050262Z","iopub.execute_input":"2025-05-14T13:29:59.050554Z","iopub.status.idle":"2025-05-14T13:31:41.958068Z","shell.execute_reply.started":"2025-05-14T13:29:59.050532Z","shell.execute_reply":"2025-05-14T13:31:41.957496Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 01:37, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.768600</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.745600</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.575800</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.449500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.394700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_model/tokenizer_config.json',\n './fine_tuned_model/special_tokens_map.json',\n './fine_tuned_model/tokenizer.model',\n './fine_tuned_model/added_tokens.json',\n './fine_tuned_model/tokenizer.json')"},"metadata":{}}],"execution_count":42}]}